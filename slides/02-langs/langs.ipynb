{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: 'Computer Languages (R, Python, Julia, C/C++)'\n",
    "subtitle: Biostat/Biomath M257\n",
    "author: Dr. Hua Zhou @ UCLA\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    theme: cosmo\n",
    "    embed-resources: true\n",
    "    number-sections: true\n",
    "    toc: true\n",
    "    toc-depth: 4\n",
    "    toc-location: left\n",
    "    code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System information (for reproducibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.8.5\n",
      "Commit 17cfb8e65ea (2023-01-08 06:45 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (arm64-apple-darwin21.5.0)\n",
      "  CPU: 12 × Apple M2 Max\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-13.0.1 (ORCJIT, apple-m1)\n",
      "  Threads: 8 on 8 virtual cores\n",
      "Environment:\n",
      "  JULIA_NUM_THREADS = 8\n",
      "  JULIA_EDITOR = code\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/github.com/ucla-biostat-257/2023spring/slides/02-langs`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/Documents/github.com/ucla-biostat-257/2023spring/slides/02-langs/Project.toml`\n",
      " \u001b[90m [6e4b80f9] \u001b[39mBenchmarkTools v1.3.2\n",
      " \u001b[90m [31c24e10] \u001b[39mDistributions v0.25.87\n",
      " \u001b[90m [bdcacae8] \u001b[39mLoopVectorization v0.12.157\n",
      " \u001b[90m [438e738f] \u001b[39mPyCall v1.95.1\n",
      " \u001b[90m [6f49c342] \u001b[39mRCall v0.13.14\n",
      " \u001b[90m [8f399da3] \u001b[39mLibdl\n",
      " \u001b[90m [9a3f8284] \u001b[39mRandom\n",
      " \u001b[90m [10745b16] \u001b[39mStatistics\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we review some popular computer languages commonly used in computational statistics. We want to understand why some languages are faster than others and what are the remedies for the slow languages.\n",
    "\n",
    "## Types of computer languages\n",
    "\n",
    "* **Compiled languages** (low-level languages): C/C++, Fortran, ... \n",
    "  - Directly compiled to machine code that is executed by CPU \n",
    "  - Pros: fast, memory efficient\n",
    "  - Cons: longer development time, hard to debug\n",
    "\n",
    "* **Interpreted language** (high-level languages): R, Matlab, Python, SAS IML, JavaScript, ... \n",
    "  - Interpreted by interpreter\n",
    "  - Pros: fast prototyping\n",
    "  - Cons: excruciatingly slow for loops\n",
    "\n",
    "* Mixed (dynamic) languages: Matlab (JIT), R (`compiler` package), Julia, Cython, JAVA, ...\n",
    "  - Pros and cons: between the compiled and interpreted languages\n",
    "\n",
    "* Script languages: Linux shell scripts, Perl, ...\n",
    "  - Extremely useful for some data preprocessing and manipulation\n",
    "\n",
    "* Database languages: SQL, Hive (Hadoop).  \n",
    "  - Data analysis *never* happens if we do not know how to retrieve data from databases  \n",
    "  \n",
    "  [203B (Introduction to Data Science)](https://ucla-biostat-203b.github.io/2023winter/schedule/schedule.html) covers some basics on scripting and database.\n",
    "\n",
    "## How high-level languages work?\n",
    "\n",
    "Comics: [The Life of a Bytecode Language](https://betterprogramming.pub/the-life-of-a-bytecode-language-fca666928e7b)\n",
    "\n",
    "- Typical execution of a high-level language such as R, Python, and Matlab.\n",
    "\n",
    "<img src=\"./r-bytecode.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "- To improve efficiency of interpreted languages such as R or Matlab, conventional wisdom is to avoid loops as much as possible. Aka, **vectorize code**\n",
    "> The only loop you are allowed to have is that for an iterative algorithm.\n",
    "\n",
    "- When looping is unavoidable, need to code in C, C++, or Fortran. This creates the notorious **two language problem**  \n",
    "Success stories: the popular `glmnet` package in R is coded in Fortran; `tidyverse` and `data.table` packages use a lot RCpp/C++.\n",
    "\n",
    "<img src=\"./two_language_problem.jpg\" align=\"center\" width=\"600\"/>\n",
    "\n",
    "- High-level languages have made many efforts to bring themselves closer to the performance of low-level languages such as C, C++, or Fortran, with a variety levels of success.   \n",
    "    - Matlab has employed JIT (just-in-time compilation) technology since 2002.  \n",
    "    - Since R 3.4.0 (Apr 2017), the JIT bytecode compiler is enabled by default at its level 3.   \n",
    "    - Cython is a compiler system based on Python.  \n",
    "\n",
    "- Modern languages such as Julia tries to solve the two language problem. That is to achieve efficiency without vectorizing code.\n",
    "\n",
    "- Julia execution.\n",
    "\n",
    "<img src=\"./julia_compile.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "<img src=\"./julia_introspect.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "## Gibbs sampler example by Doug Bates\n",
    "\n",
    "- Doug Bates (member of R-Core, author of popular R packages `Matrix`, `lme4`, `RcppEigen`, etc)\n",
    "    \n",
    "    > As some of you may know, I have had a (rather late) mid-life crisis and run off with another language called Julia.   \n",
    "    >\n",
    "    > -- <cite>Doug Bates (on the `knitr` Google Group)</cite>\n",
    "\n",
    "- An example from Dr. Doug Bates's slides [Julia for R Programmers](http://www.stat.wisc.edu/~bates/JuliaForRProgrammers.pdf).\n",
    "\n",
    "- The task is to create a Gibbs sampler for the density  \n",
    "$$\n",
    "f(x, y) = k x^2 \\exp(- x y^2 - y^2 + 2y - 4x), \\quad x > 0\n",
    "$$\n",
    "using the conditional distributions\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "  X | Y &\\sim& \\Gamma \\left( 3, \\frac{1}{y^2 + 4} \\right) \\\\\n",
    "  Y | X &\\sim& N \\left(\\frac{1}{1+x}, \\frac{1}{2(1+x)} \\right).\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "* R solution. The `RCall.jl` package allows us to execute R code without leaving the `Julia` environment. We first define an R function `Rgibbs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "R version 4.2.2 (2022-10-31)\n",
       "Platform: aarch64-apple-darwin20 (64-bit)\n",
       "Running under: macOS Ventura 13.3.1\n",
       "\n",
       "Matrix products: default\n",
       "LAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\n",
       "\n",
       "locale:\n",
       "[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n",
       "\n",
       "attached base packages:\n",
       "[1] stats     graphics  grDevices utils     datasets  methods   base     \n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       "[1] compiler_4.2.2\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "# show R information\n",
    "R\"\"\"\n",
    "sessionInfo()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{ClosSxp}\n",
       "function (N, thin) \n",
       "{\n",
       "    mat <- matrix(0, nrow = N, ncol = 2)\n",
       "    x <- y <- 0\n",
       "    for (i in 1:N) {\n",
       "        for (j in 1:thin) {\n",
       "            x <- rgamma(1, 3, y * y + 4)\n",
       "            y <- rnorm(1, 1/(x + 1), 1/sqrt(2 * (x + 1)))\n",
       "        }\n",
       "        mat[i, ] <- c(x, y)\n",
       "    }\n",
       "    mat\n",
       "}\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function for Gibbs sampling\n",
    "\n",
    "R\"\"\"\n",
    "library(Matrix)\n",
    "\n",
    "Rgibbs <- function(N, thin) {\n",
    "  mat <- matrix(0, nrow=N, ncol=2)\n",
    "  x <- y <- 0\n",
    "  for (i in 1:N) {\n",
    "    for (j in 1:thin) {\n",
    "      x <- rgamma(1, 3, y * y + 4) # 3rd arg is rate\n",
    "      y <- rnorm(1, 1 / (x + 1), 1 / sqrt(2 * (x + 1)))\n",
    "    }\n",
    "    mat[i,] <- c(x, y)\n",
    "  }\n",
    "  mat\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a sample of size 10,000 with a thinning of 500. How long does it take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{RealSxp}\n",
       "   user  system elapsed \n",
       "  9.605   0.574  10.180 \n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "system.time(Rgibbs(10000, 500))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is a Julia function for the same Gibbs sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jgibbs (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "\n",
    "function jgibbs(N, thin)\n",
    "    mat = zeros(N, 2)\n",
    "    x = y = 0.0\n",
    "    for i in 1:N\n",
    "        for j in 1:thin\n",
    "            x = rand(Gamma(3, 1 / (y * y + 4)))\n",
    "            y = rand(Normal(1 / (x + 1), 1 / sqrt(2(x + 1))))\n",
    "        end\n",
    "        mat[i, 1] = x\n",
    "        mat[i, 2] = y\n",
    "    end\n",
    "    mat\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the same number of samples. How long does it take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.107618"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jgibbs(100, 5); # warm-up\n",
    "@elapsed jgibbs(10000, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see 40-80 fold speed up of `Julia` over `R` on this example, **with similar coding effort**!\n",
    "\n",
    "## Comparing C, C++, R, Python, and Julia\n",
    "\n",
    "To better understand how these languages work, we consider a simple task: summing a vector.\n",
    "\n",
    "Let's first generate data: 1 million double precision numbers from uniform [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500156.3977288406"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "\n",
    "Random.seed!(257) # seed\n",
    "x = rand(1_000_000) # 1 million random numbers in [0, 1)\n",
    "sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class, we extensively use package `BenchmarkTools.jl` for robust benchmarking. It's the analog of the `microbenchmark` or `bench` package in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C\n",
    "\n",
    "We would use the low-level C code as the baseline for copmarison. In Julia, we can easily run compiled C code using the `ccall` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clang: warning: argument unused during compilation: '-msse3' [-Wunused-command-line-argument]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "c_sum (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Libdl\n",
    "\n",
    "C_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "\n",
    "double c_sum(size_t n, double *X) {\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        s += X[i];\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "const Clib = tempname()   # make a temporary file\n",
    "\n",
    "# compile to a shared library by piping C_code to gcc\n",
    "# (works only if you have gcc installed):\n",
    "open(`gcc -std=c99 -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code) \n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum(X :: Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500156.39772885485"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it gives same answer\n",
    "c_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 6129 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m811.583 μs\u001b[22m\u001b[39m … \u001b[35m960.708 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m811.750 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m815.030 μs\u001b[22m\u001b[39m ± \u001b[32m  9.003 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m▇\u001b[32m▄\u001b[39m\u001b[39m \u001b[39m▄\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
       "  \u001b[34m█\u001b[39m\u001b[39m▅\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▁\u001b[39m▆\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▅\u001b[39m▁\u001b[39m▃\u001b[39m▄\u001b[39m \u001b[39m█\n",
       "  812 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        853 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dollar sign to interpolate array x into local scope for benchmarking\n",
    "bm = @benchmark c_sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81175"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a dictionary to store median runtime (in milliseconds)\n",
    "benchmark_result = Dict() \n",
    "\n",
    "# store median runtime (in milliseconds)\n",
    "benchmark_result[\"C\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R, buildin sum\n",
    "\n",
    "Next we compare to the build in `sum` function in R, which is implemented using C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mRCall.jl: ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m✔ dplyr     1.1.0     ✔ readr     2.1.4\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m✔ forcats   1.0.0     ✔ stringr   1.5.0\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m✔ purrr     1.0.1     \n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m✖ tidyr::expand() masks Matrix::expand()\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m✖ dplyr::filter() masks stats::filter()\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m✖ dplyr::lag()    masks stats::lag()\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m✖ tidyr::pack()   masks Matrix::pack()\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m✖ tidyr::unpack() masks Matrix::unpack()\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ RCall ~/.julia/packages/RCall/Wyd74/src/io.jl:172\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 1 × 13\n",
      "  expression      min   median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc\n",
      "  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> <int> <dbl>\n",
      "1 sum(y)       1.33ms   1.33ms      746.        0B        0   373     0\n",
      "  total_time result    memory             time             gc                \n",
      "    <bch:tm> <list>    <list>             <list>           <list>            \n",
      "1      500ms <dbl [1]> <Rprofmem [0 × 3]> <bench_tm [373]> <tibble [373 × 3]>\n"
     ]
    }
   ],
   "source": [
    "R\"\"\"\n",
    "library(bench)\n",
    "library(tidyverse)\n",
    "\n",
    "# interpolate x into R workspace\n",
    "y <- $x\n",
    "rbm_builtin <- bench::mark(sum(y)) %>%\n",
    "  print(width = Inf)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3345909828785807"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "@rget rbm_builtin # dataframe\n",
    "benchmark_result[\"R builtin\"] = median(rbm_builtin[!, :median]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R, handwritten loop\n",
    "\n",
    "Handwritten loop in R is much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 1 × 13\n",
      "  expression      min   median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc\n",
      "  <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> <int> <dbl>\n",
      "1 sum_r(y)     7.65ms   7.75ms      128.    13.1KB        0    65     0\n",
      "  total_time result    memory              time            gc               \n",
      "    <bch:tm> <list>    <list>              <list>          <list>           \n",
      "1      506ms <dbl [1]> <Rprofmem [36 × 3]> <bench_tm [65]> <tibble [65 × 3]>\n"
     ]
    }
   ],
   "source": [
    "R\"\"\"\n",
    "sum_r <- function(x) {\n",
    "  s <- 0\n",
    "  for (xi in x) {\n",
    "    s <- s + xi\n",
    "  }\n",
    "  s\n",
    "}\n",
    "library(bench)\n",
    "y <- $x\n",
    "rbm_loop <- bench::mark(sum_r(y)) %>%\n",
    "  print(width = Inf)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.746868010144681"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "@rget rbm_loop # dataframe\n",
    "benchmark_result[\"R loop\"] = median(rbm_loop[!, :median]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R, Rcpp\n",
    "\n",
    "Rcpp package provides an easy way to incorporate C++ code in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{ClosSxp}\n",
       "function (x) \n",
       ".Call(<pointer: 0x2c81fcd00>, x)\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "library(Rcpp)\n",
    "\n",
    "cppFunction('double rcpp_sum(NumericVector x) {\n",
    "  int n = x.size();\n",
    "  double total = 0;\n",
    "  for(int i = 0; i < n; ++i) {\n",
    "    total += x[i];\n",
    "  }\n",
    "  return total;\n",
    "}')\n",
    "\n",
    "rcpp_sum\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 1 × 13\n",
      "  expression       min   median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc\n",
      "  <bch:expr>  <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl> <int> <dbl>\n",
      "1 rcpp_sum(y)    799µs    803µs     1234.    2.49KB        0   617     0\n",
      "  total_time result    memory             time             gc                \n",
      "    <bch:tm> <list>    <list>             <list>           <list>            \n",
      "1      500ms <dbl [1]> <Rprofmem [1 × 3]> <bench_tm [617]> <tibble [617 × 3]>\n"
     ]
    }
   ],
   "source": [
    "R\"\"\"\n",
    "rbm_rcpp <- bench::mark(rcpp_sum(y)) %>%\n",
    "  print(width = Inf)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8029030286706984"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "@rget rbm_rcpp # dataframe\n",
    "benchmark_result[\"R Rcpp\"] = median(rbm_rcpp[!, :median]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, builtin sum\n",
    "\n",
    "Built in function `sum` in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"3.10.9\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "\n",
    "PyCall.pyversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 135 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m36.486 ms\u001b[22m\u001b[39m … \u001b[35m 37.890 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m37.058 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m37.095 ms\u001b[22m\u001b[39m ± \u001b[32m163.792 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m▂\u001b[39m▄\u001b[39m█\u001b[39m▇\u001b[34m▄\u001b[39m\u001b[39m \u001b[32m▄\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▆\u001b[32m█\u001b[39m\u001b[39m▆\u001b[39m▆\u001b[39m▃\u001b[39m▁\u001b[39m▄\u001b[39m▅\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▁\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m \u001b[39m▃\n",
       "  36.5 ms\u001b[90m         Histogram: frequency by time\u001b[39m         37.7 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m240 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")\n",
    "bm = @benchmark $pysum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.058458"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python builtin\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, handwritten loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 110 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m45.192 ms\u001b[22m\u001b[39m … \u001b[35m 46.912 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m45.812 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m45.784 ms\u001b[22m\u001b[39m ± \u001b[32m287.684 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m \u001b[32m▇\u001b[39m\u001b[34m▄\u001b[39m\u001b[39m▇\u001b[39m█\u001b[39m \u001b[39m▃\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▅\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▃\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m▅\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▅\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m \u001b[39m▃\n",
       "  45.2 ms\u001b[90m         Histogram: frequency by time\u001b[39m         46.7 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m240 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py\"\"\"\n",
    "def py_sum(A):\n",
    "    s = 0.0\n",
    "    for a in A:\n",
    "        s += a\n",
    "    return s\n",
    "\"\"\"\n",
    "\n",
    "sum_py = py\"py_sum\"\n",
    "\n",
    "bm = @benchmark $sum_py($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.812208"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python loop\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, numpy\n",
    "\n",
    "Numpy is the high-performance scientific computing library for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function sum at 0x2c96bd3f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring in sum function from Numpy \n",
    "numpy_sum = pyimport(\"numpy\").\"sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m159.708 μs\u001b[22m\u001b[39m … \u001b[35m313.833 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m174.000 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m172.386 μs\u001b[22m\u001b[39m ± \u001b[32m  5.816 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m▂\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m▅\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▇\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[32m▆\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m \u001b[39m█\n",
       "  160 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        185 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m240 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm = @benchmark $numpy_sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.174"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python numpy\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy performance is on a par with Julia build-in sum function. Both are about 3 times faster than C, possibly because of usage of [SIMD](https://en.wikipedia.org/wiki/SIMD).\n",
    "\n",
    "### Julia, builtin sum\n",
    "\n",
    "`@time`, `@elapsed`, `@allocated` macros in Julia report run times and memory allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000174 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500156.3977288406"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(x) # no compilation time after first run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more robust benchmarking, we use BenchmarkTools.jl package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m159.291 μs\u001b[22m\u001b[39m … \u001b[35m203.583 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m159.459 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m160.519 μs\u001b[22m\u001b[39m ± \u001b[32m  2.727 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m█\u001b[34m▆\u001b[39m\u001b[39m▁\u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m▅\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
       "  \u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[32m▄\u001b[39m\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▁\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  159 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        173 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm = @benchmark sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.159459"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_result[\"Julia builtin\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Julia, handwritten loop\n",
    "\n",
    "Let's also write a loop and benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 6130 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m811.583 μs\u001b[22m\u001b[39m … \u001b[35m940.250 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m811.792 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m814.884 μs\u001b[22m\u001b[39m ± \u001b[32m  7.989 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[32m▇\u001b[39m\u001b[39m \u001b[39m \u001b[39m▄\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
       "  \u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▄\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▅\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▄\u001b[39m▆\u001b[39m▄\u001b[39m▆\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▇\u001b[39m \u001b[39m█\n",
       "  812 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        851 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function jl_sum(A)\n",
    "    s = zero(eltype(A))\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    s\n",
    "end\n",
    "\n",
    "bm = @benchmark jl_sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811792"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_result[\"Julia loop\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: annotate the loop by [`@simd`](https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-annotations-1) or `LoopVectorization.@turbo` and benchmark again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m82.166 μs\u001b[22m\u001b[39m … \u001b[35m142.542 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m89.250 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m87.171 μs\u001b[22m\u001b[39m ± \u001b[32m  3.736 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m▇\u001b[39m▆\u001b[39m▃\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▅\u001b[34m█\u001b[39m\u001b[39m▄\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▄\u001b[32m▅\u001b[39m\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▅\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m█\u001b[39m \u001b[39m█\n",
       "  82.2 μs\u001b[90m       \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      94.7 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LoopVectorization\n",
    "\n",
    "function jl_sum_turbo(A)\n",
    "    s = zero(eltype(A))\n",
    "    @turbo for i in eachindex(A)\n",
    "      s += A[i]\n",
    "    end\n",
    "    s\n",
    "end\n",
    "\n",
    "bm = @benchmark jl_sum_turbo($x)\n",
    "bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08925"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_result[\"Julia turbo\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@tturbo` macro turns on multi-threading. Not for this to function, Julia needs to be started with multi-threading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m31.500 μs\u001b[22m\u001b[39m … \u001b[35m148.459 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m32.541 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m32.772 μs\u001b[22m\u001b[39m ± \u001b[32m  2.423 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▅\u001b[39m█\u001b[34m▃\u001b[39m\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
       "  \u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▇\u001b[32m▇\u001b[39m\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▅\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▃\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m█\u001b[39m▃\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▅\u001b[39m▃\u001b[39m▄\u001b[39m▇\u001b[39m \u001b[39m█\n",
       "  31.5 μs\u001b[90m       \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      37.9 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function jl_sum_tturbo(A)\n",
    "    s = zero(eltype(A))\n",
    "    @tturbo for i in eachindex(A)\n",
    "      s += A[i]\n",
    "    end\n",
    "    s\n",
    "end\n",
    "\n",
    "bm = @benchmark jl_sum_tturbo($x)\n",
    "bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032541"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_result[\"Julia tturbo\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Vector{Pair{Any, Any}}:\n",
       "   \"Julia tturbo\" => 0.032541\n",
       "    \"Julia turbo\" => 0.08925\n",
       "  \"Julia builtin\" => 0.159459\n",
       "   \"Python numpy\" => 0.174\n",
       "         \"R Rcpp\" => 0.8029030286706984\n",
       "              \"C\" => 0.81175\n",
       "     \"Julia loop\" => 0.811792\n",
       "      \"R builtin\" => 1.3345909828785807\n",
       "         \"R loop\" => 7.746868010144681\n",
       " \"Python builtin\" => 37.058458\n",
       "    \"Python loop\" => 45.812208"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(collect(benchmark_result), by = x -> x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `C`, `R builtin` are the baseline C performance (gold standard).\n",
    "\n",
    "* `Python builtin` and `Python loop` are >50 fold slower than C because the loop is interpreted.\n",
    "\n",
    "* `R loop` is about 10 times slower than C and indicates the performance of JIT bytecode generated by its `compiler` package (turned on by default since R v3.4.0 (Apr 2017)). \n",
    "\n",
    "* `Julia loop` is close to C performance, because Julia code is JIT compiled.\n",
    "\n",
    "* `Julia builtin`, `Python numpy`, and `Julia turbo` are 4-5 fold faster than C because of SIMD.\n",
    "\n",
    "* `@turbo` (SIMD) and `@tturbo` (multithreading+SIMD), offered by the LoopVectorization.jl package. yields the top performance on this machine.\n",
    "\n",
    "## Take home message for computational scientists\n",
    "\n",
    "- High-level language (R, Python, Matlab) programmers should be familiar with existing high-performance packages.  Don't reinvent wheels.  \n",
    "    - R: RcppEigen, tidyverse, ...   \n",
    "    - Python: numpy, scipy, ...  \n",
    "\n",
    "- In most research projects, looping is unavoidable. Then we need to use a low-level language.  \n",
    "    - R: Rcpp, ...  \n",
    "    - Python: Cython, ...  \n",
    "    \n",
    "- In this course, we use Julia, which circumvents the two language problem. So we can spend more time on algorithms, not on juggling $\\ge 2$ languages.  "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "Julia (8 threads) 1.8.5",
   "language": "julia",
   "name": "julia-_8-threads_-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "511.7391357421875px",
    "width": "251.7391357421875px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "640.4212036132812px",
    "left": "0px",
    "right": "1210.6114501953125px",
    "top": "109.57880401611328px",
    "width": "211.99728393554688px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
